{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941243dc",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0edfd2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Header Tag                           Text\n",
      "0          h1                      Main Page\n",
      "1          h1            Welcome toWikipedia\n",
      "2          h2  From today's featured article\n",
      "3          h2               Did you know ...\n",
      "4          h2                    In the news\n",
      "5          h2                    On this day\n",
      "6          h2     From today's featured list\n",
      "7          h2       Today's featured picture\n",
      "8          h2       Other areas of Wikipedia\n",
      "9          h2    Wikipedia's sister projects\n",
      "10         h2            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "def scrape_wiki(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return f\"Error during fetching the details. Status code: {response.status_code}\"\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        header1 = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        headerlist = [{\"Header Tag\": header.name, \"Text\": header.get_text(strip=True)} for header in header1]\n",
    "        df = pd.DataFrame(headerlist)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return f\"An error: {str(e)}\"\n",
    "print(scrape_wiki(url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea892b",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390ecb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during fetching the details. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    presidents_lst = soup.find_all(\"div\", class_=\"presidentListing\")\n",
    "    presi_data = []\n",
    "    for president in presidents_lst:\n",
    "        name = president.find(\"h3\").get_text(strip=True)\n",
    "        t1 = president.find(\"p\").get_text(strip=True)\n",
    "        presi_data.append({\"Name\": name, \"Term of Office\": t1})\n",
    "    df = pd.DataFrame(presi_data)\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Error during fetching the details. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3b1f7",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46df7793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Headline              Time  \\\n",
      "0           CNBC Daily Open: Big Tech earnings on tap        16 Min Ago   \n",
      "1   European stocks set to slip after notching two...        24 Min Ago   \n",
      "2   Norway defends contentious deep-sea mining as ...       2 Hours Ago   \n",
      "3   Oil prices higher after Iran-linked drone stri...       3 Hours Ago   \n",
      "4   China's luxury market is bouncing back with ne...       4 Hours Ago   \n",
      "5   China plans to merge 3 bad debt asset managers...       4 Hours Ago   \n",
      "6   Evergrande shares halted after Hong Kong court...       5 Hours Ago   \n",
      "7       CNBC Daily Open: Big Tech earnings loom large       6 Hours Ago   \n",
      "8   Singapore's central bank leaves policy unchang...       8 Hours Ago   \n",
      "9   These 6 stocks will be non-AI winners of an AI...       8 Hours Ago   \n",
      "10  Is Tesla still a buy? One CIO weighs in and na...       8 Hours Ago   \n",
      "11  Evergrande shares halt trading after Hong Kong...       8 Hours Ago   \n",
      "12  Cramer: Earnings take center stage, but don't ...       9 Hours Ago   \n",
      "13  Stock futures fall ahead of big tech earnings ...       9 Hours Ago   \n",
      "14  How much does ‘shoulder season’ travel save? W...       9 Hours Ago   \n",
      "15  Berkshire Hathaway keeps buying Liberty's Siri...      11 Hours Ago   \n",
      "16  Monthly Meeting Q&A with Jim Cramer: Health ca...      14 Hours Ago   \n",
      "17  Nikki Haley slams Trump for trying to torpedo ...      15 Hours Ago   \n",
      "18  Unions, with power and popularity rising, are ...      16 Hours Ago   \n",
      "19  Online sports betting stocks are primed for a ...      16 Hours Ago   \n",
      "20  Here's what we think about when deciding how m...      17 Hours Ago   \n",
      "21  I've spent 20 years studying how to raise succ...      17 Hours Ago   \n",
      "22  Mark Cuban: Here's the moment I knew I wouldn’...      17 Hours Ago   \n",
      "23  The 7 most popular countries for U.S. workers ...      18 Hours Ago   \n",
      "24  36-year-old quit her job to write novels—how s...      18 Hours Ago   \n",
      "25  Workers are paying to get wages early. It's 'p...      18 Hours Ago   \n",
      "26  Big pharma is preparing to lose revenue from b...      19 Hours Ago   \n",
      "27  Chinese stocks are starting to turn around. Ho...      20 Hours Ago   \n",
      "28  Earnings playbook: Your guide to the busiest w...      20 Hours Ago   \n",
      "29  Wall Street touted 5 portfolio stocks this wee...  January 27, 2024   \n",
      "\n",
      "                                            News Link  \n",
      "0   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "1   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "2   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "3   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "4   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "5   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "6   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "7   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "8   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "9   https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "10  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "11  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "12  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "13  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "14  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "15  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "16  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "17  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "18  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "19  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "20  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "21  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "22  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "23  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "24  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "25  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "26  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "27  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "28  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n",
      "29  https://www.cnbc.comhttps://www.cnbc.com/2024/...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def cnbc_news(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    news_dt = []\n",
    "    articles = soup.find_all(\"div\", {\"class\": \"LatestNews-headlineWrapper\"})\n",
    "\n",
    "    for article in articles:\n",
    "        headline = article.find(\"a\", {\"class\": \"LatestNews-headline\"}).text.strip()\n",
    "        time = article.find(\"time\").text.strip()\n",
    "        link = article.find(\"a\", {\"class\": \"LatestNews-headline\"})['href']\n",
    "\n",
    "        news_dt.append({\n",
    "            \"Headline\": headline,\n",
    "            \"Time\": time,\n",
    "            \"News Link\": \"https://www.cnbc.com\" + link\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(news_dt)\n",
    "\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "df = cnbc_news(url)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c7a32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
